{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19238,"status":"ok","timestamp":1704168296041,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"PXcDmsj0VKh4","outputId":"57467339-7355-4a68-9f12-28b924dc6ee9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704168296041,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"OtnCUplRVPR9","outputId":"f54d443f-ba0f-4b68-9a4b-5d103efeb63c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1FbM89xH1dKPtK3SG5wd4NoMu_YTXTHzo/transfer_learning\n"]}],"source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/transfer_learning/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49291,"status":"ok","timestamp":1704168345330,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"8Za36cPaVQJa","outputId":"b59cff59-5add-455e-a79b-d30781e4b31b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing /content/drive/.shortcut-targets-by-id/1FbM89xH1dKPtK3SG5wd4NoMu_YTXTHzo/transfer_learning\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (1.23.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (0.16.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (2.31.0)\n","Collecting wandb (from unlabeled-extrapolation==0.0.1)\n","  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (1.5.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (3.9.0)\n","Collecting strconv (from unlabeled-extrapolation==0.0.1)\n","  Downloading strconv-0.4.2.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (1.11.4)\n","Collecting cdsapi (from unlabeled-extrapolation==0.0.1)\n","  Downloading cdsapi-0.6.1.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting uncertainty-calibration (from unlabeled-extrapolation==0.0.1)\n","  Downloading uncertainty-calibration-0.1.4.tar.gz (15 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (2.15.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (4.8.0.76)\n","Collecting robustness (from unlabeled-extrapolation==0.0.1)\n","  Downloading robustness-1.2.1.post2-py3-none-any.whl (95 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (3.2.1)\n","Collecting ftfy (from unlabeled-extrapolation==0.0.1)\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from unlabeled-extrapolation==0.0.1) (2023.6.3)\n","Collecting timm (from unlabeled-extrapolation==0.0.1)\n","  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wilds (from unlabeled-extrapolation==0.0.1)\n","  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unlabeled-extrapolation==0.0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unlabeled-extrapolation==0.0.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unlabeled-extrapolation==0.0.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unlabeled-extrapolation==0.0.1) (2023.11.17)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->unlabeled-extrapolation==0.0.1) (0.2.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unlabeled-extrapolation==0.0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unlabeled-extrapolation==0.0.1) (2023.3.post1)\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from robustness->unlabeled-extrapolation==0.0.1) (1.60.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from robustness->unlabeled-extrapolation==0.0.1) (5.9.5)\n","Collecting gitpython (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting py3nvml (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cox (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading cox-0.1.post3-py3-none-any.whl (18 kB)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from robustness->unlabeled-extrapolation==0.0.1) (0.12.2)\n","Collecting GPUtil (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dill (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboardX (from robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (from robustness->unlabeled-extrapolation==0.0.1) (3.8.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->unlabeled-extrapolation==0.0.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->unlabeled-extrapolation==0.0.1) (3.2.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (1.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (3.5.1)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->unlabeled-extrapolation==0.0.1) (3.0.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->unlabeled-extrapolation==0.0.1) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm->unlabeled-extrapolation==0.0.1) (0.19.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->unlabeled-extrapolation==0.0.1) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->unlabeled-extrapolation==0.0.1) (2.1.0)\n","Collecting parameterized (from uncertainty-calibration->unlabeled-extrapolation==0.0.1)\n","  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->unlabeled-extrapolation==0.0.1) (8.1.7)\n","Collecting sentry-sdk>=1.0.0 (from wandb->unlabeled-extrapolation==0.0.1)\n","  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->unlabeled-extrapolation==0.0.1)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle (from wandb->unlabeled-extrapolation==0.0.1)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->unlabeled-extrapolation==0.0.1) (1.4.4)\n","Collecting ogb>=1.2.6 (from wilds->unlabeled-extrapolation==0.0.1)\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting outdated>=0.2.0 (from wilds->unlabeled-extrapolation==0.0.1)\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Collecting gitdb<5,>=4.0.1 (from gitpython->robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->unlabeled-extrapolation==0.0.1) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->unlabeled-extrapolation==0.0.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->unlabeled-extrapolation==0.0.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->unlabeled-extrapolation==0.0.1) (1.3.1)\n","Collecting littleutils (from outdated>=0.2.0->wilds->unlabeled-extrapolation==0.0.1)\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->unlabeled-extrapolation==0.0.1) (2.1.3)\n","Collecting xmltodict (from py3nvml->robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->unlabeled-extrapolation==0.0.1) (1.3.0)\n","Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables->robustness->unlabeled-extrapolation==0.0.1) (3.0.6)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables->robustness->unlabeled-extrapolation==0.0.1) (2.8.8)\n","Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables->robustness->unlabeled-extrapolation==0.0.1) (2.0.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables->robustness->unlabeled-extrapolation==0.0.1) (9.0.0)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2~=2.0.0->tables->robustness->unlabeled-extrapolation==0.0.1) (1.0.7)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->robustness->unlabeled-extrapolation==0.0.1)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->unlabeled-extrapolation==0.0.1) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->unlabeled-extrapolation==0.0.1) (3.2.2)\n","Building wheels for collected packages: unlabeled-extrapolation, cdsapi, strconv, uncertainty-calibration, GPUtil, littleutils\n","  Building wheel for unlabeled-extrapolation (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unlabeled-extrapolation: filename=unlabeled_extrapolation-0.0.1-py3-none-any.whl size=247043 sha256=30b2508f5c862f169f55f71abbd966bcc85a9b3af119c8efd125624cbea242f9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yavdqb71/wheels/31/b7/0d/69c9d7d8934005dae917be21f35057021a0881c1900e99fdb9\n","  Building wheel for cdsapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cdsapi: filename=cdsapi-0.6.1-py2.py3-none-any.whl size=12008 sha256=b5243d175cb37cf4ae6cf9dd8adaa05c111e3fcb324cbd46d9ca2f09ceb0beef\n","  Stored in directory: /root/.cache/pip/wheels/7c/63/08/45461d6f6636c1aba7846828d8c787a064073945048f76d44a\n","  Building wheel for strconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for strconv: filename=strconv-0.4.2-py3-none-any.whl size=3730 sha256=05352845a06842784ded9cffd0a9fcbdb2e122e8cf195596ae4e55ba90c47bb3\n","  Stored in directory: /root/.cache/pip/wheels/d4/2c/71/b5577cc47d3a818af598640de45b6e744b8a6070fe0d25a4f8\n","  Building wheel for uncertainty-calibration (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for uncertainty-calibration: filename=uncertainty_calibration-0.1.4-py3-none-any.whl size=14201 sha256=60fff02cab5012d38eca007fbfb19a63c0d78cb1619d3b32c11901106d974c5c\n","  Stored in directory: /root/.cache/pip/wheels/9c/fb/74/93a4d13a3aa8e85f5f2b570114d0c19c7e1e1366f901c9d1c0\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=f604a1405d5a6cafa980e2c868e7855765b37d769ee98d71277fac532ab9643f\n","  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=d261125bd5ea2a5dcc62ca64a99188fc782faf6701f775e232bc5771abe15059\n","  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n","Successfully built unlabeled-extrapolation cdsapi strconv uncertainty-calibration GPUtil littleutils\n","Installing collected packages: strconv, littleutils, GPUtil, xmltodict, tensorboardX, smmap, setproctitle, sentry-sdk, parameterized, ftfy, docker-pycreds, dill, py3nvml, outdated, gitdb, cdsapi, uncertainty-calibration, ogb, gitpython, wilds, wandb, timm, cox, robustness, unlabeled-extrapolation\n","Successfully installed GPUtil-1.4.0 cdsapi-0.6.1 cox-0.1.post3 dill-0.3.7 docker-pycreds-0.4.0 ftfy-6.1.3 gitdb-4.0.11 gitpython-3.1.40 littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2 parameterized-0.9.0 py3nvml-0.2.7 robustness-1.2.1.post2 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 strconv-0.4.2 tensorboardX-2.6.2.2 timm-0.9.12 uncertainty-calibration-0.1.4 unlabeled-extrapolation-0.0.1 wandb-0.16.1 wilds-2.0.0 xmltodict-0.13.0\n"]}],"source":["%pip install ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12407,"status":"ok","timestamp":1704168357733,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"hazSV8GfVRVA","outputId":"c61eb06c-e9f7-41f9-e3e0-8b6ee46b7433"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/shuqike/quinine.git\n","  Cloning https://github.com/shuqike/quinine.git to /tmp/pip-req-build-va67mco6\n","  Running command git clone --filter=blob:none --quiet https://github.com/shuqike/quinine.git /tmp/pip-req-build-va67mco6\n","  Resolved https://github.com/shuqike/quinine.git to commit 77b7195f6d0577e479eda70f54c4b0e3902d8165\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Cerberus (from quinine==0.3.0)\n","  Downloading Cerberus-1.3.5-py3-none-any.whl (30 kB)\n","Collecting cytoolz (from quinine==0.3.0)\n","  Downloading cytoolz-0.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting funcy (from quinine==0.3.0)\n","  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n","Requirement already satisfied: gin_config in /usr/local/lib/python3.10/dist-packages (from quinine==0.3.0) (0.5.0)\n","Collecting munch (from quinine==0.3.0)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Collecting toposort (from quinine==0.3.0)\n","  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz->quinine==0.3.0) (0.12.0)\n","Building wheels for collected packages: quinine\n","  Building wheel for quinine (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for quinine: filename=quinine-0.3.0-py3-none-any.whl size=20796 sha256=e19f8b9de53409e07594f88f050d67308a06ec9c771100a41fe28ca19e2d0577\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jcfggb_r/wheels/4a/c8/cc/851a7103361e64cb16f5045167d8a5063bb57d5813504f8777\n","Successfully built quinine\n","Installing collected packages: toposort, funcy, Cerberus, munch, cytoolz, quinine\n","Successfully installed Cerberus-1.3.5 cytoolz-0.12.2 funcy-2.0 munch-4.0.0 quinine-0.3.0 toposort-1.10\n"]}],"source":["%pip install git+https://github.com/shuqike/quinine.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5987,"status":"ok","timestamp":1704168363709,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"xO6iZmOijNcd","outputId":"16ee0899-fdae-4d68-f00e-5408bcd078bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu121)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: opacus\n","Successfully installed opacus-1.4.0\n"]}],"source":["%pip install opacus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12021,"status":"ok","timestamp":1704168375728,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"},"user_tz":-480},"id":"QgK7P28EVUie","outputId":"1fe0d1d8-f2eb-450f-f5e6-cefb4f348bba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/awslabs/fast-differential-privacy.git\n","  Cloning https://github.com/awslabs/fast-differential-privacy.git to /tmp/pip-req-build-i7tiiqx4\n","  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy.git /tmp/pip-req-build-i7tiiqx4\n","  Resolved https://github.com/awslabs/fast-differential-privacy.git to commit 053a82df69e48698053570e90bc24cd8bba26daf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastDP\n","  Building wheel for fastDP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastDP: filename=fastDP-1.1.0-py3-none-any.whl size=101667 sha256=349ade1410a8bf98cc7d42661c426caa11546804489f178f80b133ea87893b8a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ndwj06cx/wheels/09/8c/77/183c75a4d820b35303869508fe5f4b2b39556fe947c4983da8\n","Successfully built fastDP\n","Installing collected packages: fastDP\n","Successfully installed fastDP-1.1.0\n"]}],"source":["%pip install git+https://github.com/awslabs/fast-differential-privacy.git"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GICgLUhmhZp_","executionInfo":{"status":"ok","timestamp":1704174565361,"user_tz":-480,"elapsed":4194969,"user":{"displayName":"Shuqi Ke","userId":"16224521071346683343"}},"outputId":"fe0eaa7b-8090-4b21-d9a3-1c97f2b8312c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /u/scr/ananya//cifar10_dataset/cifar-10-python.tar.gz\n","100% 170498071/170498071 [00:01<00:00, 102008972.31it/s]\n","Extracting /u/scr/ananya//cifar10_dataset/cifar-10-python.tar.gz to /u/scr/ananya//cifar10_dataset\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Files already downloaded and verified\n","debug Parameter containing:\n","tensor([[ 8.1851e-03, -7.8123e-04, -1.3914e-02,  ..., -1.6385e-02,\n","          6.1499e-03, -7.7952e-03],\n","        [-5.0221e-03, -2.1486e-02,  1.0006e-02,  ..., -7.6706e-03,\n","          1.6140e-02,  4.0036e-03],\n","        [ 8.6662e-04, -2.1731e-02, -1.3133e-02,  ..., -1.3780e-02,\n","          3.0556e-05,  1.6708e-02],\n","        ...,\n","        [-8.2857e-04, -1.6858e-03, -1.0511e-03,  ..., -1.9183e-02,\n","         -1.1904e-02, -6.6545e-03],\n","        [ 1.4608e-02, -6.7522e-04, -1.3546e-02,  ...,  2.9816e-03,\n","          1.5819e-02, -2.0960e-02],\n","        [-2.6201e-03, -1.2098e-02,  5.5198e-04,  ..., -6.1534e-03,\n","         -1.6895e-03,  3.1690e-03]], device='cuda:0', requires_grad=True)\n","debug head param Parameter containing:\n","tensor([[ 8.1851e-03, -7.8123e-04, -1.3914e-02,  ..., -1.6385e-02,\n","          6.1499e-03, -7.7952e-03],\n","        [-5.0221e-03, -2.1486e-02,  1.0006e-02,  ..., -7.6706e-03,\n","          1.6140e-02,  4.0036e-03],\n","        [ 8.6662e-04, -2.1731e-02, -1.3133e-02,  ..., -1.3780e-02,\n","          3.0556e-05,  1.6708e-02],\n","        ...,\n","        [-8.2857e-04, -1.6858e-03, -1.0511e-03,  ..., -1.9183e-02,\n","         -1.1904e-02, -6.6545e-03],\n","        [ 1.4608e-02, -6.7522e-04, -1.3546e-02,  ...,  2.9816e-03,\n","          1.5819e-02, -2.0960e-02],\n","        [-2.6201e-03, -1.2098e-02,  5.5198e-04,  ..., -6.1534e-03,\n","         -1.6895e-03,  3.1690e-03]], device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","debug head param Parameter containing:\n","tensor([[ 0.0167, -0.0102, -0.0204,  ..., -0.0146,  0.0137, -0.0098],\n","        [-0.0119, -0.0220,  0.0060,  ..., -0.0113,  0.0168,  0.0019],\n","        [ 0.0020, -0.0211, -0.0195,  ..., -0.0119,  0.0006,  0.0145],\n","        ...,\n","        [-0.0079, -0.0054,  0.0020,  ..., -0.0070, -0.0159,  0.0055],\n","        [ 0.0167, -0.0098, -0.0187,  ...,  0.0076,  0.0186, -0.0212],\n","        [-0.0141, -0.0185, -0.0001,  ..., -0.0056,  0.0034,  0.0063]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","debug head param Parameter containing:\n","tensor([[ 0.0234, -0.0176, -0.0324,  ..., -0.0135,  0.0199, -0.0163],\n","        [-0.0141, -0.0239,  0.0014,  ..., -0.0187,  0.0167,  0.0026],\n","        [ 0.0016, -0.0251, -0.0261,  ..., -0.0124,  0.0002,  0.0147],\n","        ...,\n","        [-0.0118, -0.0123,  0.0082,  ...,  0.0040, -0.0191,  0.0084],\n","        [ 0.0185, -0.0151, -0.0300,  ...,  0.0040,  0.0258, -0.0266],\n","        [-0.0158, -0.0285, -0.0037,  ..., -0.0182, -0.0029,  0.0101]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","debug head param Parameter containing:\n","tensor([[ 0.0343, -0.0529, -0.0641,  ..., -0.0164,  0.0354, -0.0224],\n","        [-0.0207, -0.0231, -0.0116,  ..., -0.0272,  0.0237, -0.0061],\n","        [ 0.0053, -0.0329, -0.0278,  ..., -0.0044,  0.0053,  0.0102],\n","        ...,\n","        [-0.0209, -0.0333,  0.0172,  ...,  0.0287, -0.0296,  0.0133],\n","        [ 0.0276, -0.0354, -0.0404,  ...,  0.0016,  0.0351, -0.0376],\n","        [-0.0321, -0.0396, -0.0097,  ..., -0.0188, -0.0030,  0.0183]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","debug head param Parameter containing:\n","tensor([[ 0.0355, -0.0539, -0.0626,  ..., -0.0170,  0.0359, -0.0243],\n","        [-0.0181, -0.0239, -0.0119,  ..., -0.0274,  0.0246, -0.0075],\n","        [ 0.0054, -0.0331, -0.0266,  ..., -0.0044,  0.0066,  0.0090],\n","        ...,\n","        [-0.0229, -0.0339,  0.0173,  ...,  0.0304, -0.0291,  0.0154],\n","        [ 0.0294, -0.0367, -0.0383,  ...,  0.0016,  0.0335, -0.0367],\n","        [-0.0323, -0.0405, -0.0090,  ..., -0.0194, -0.0021,  0.0179]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","debug head param Parameter containing:\n","tensor([[ 0.0352, -0.0543, -0.0636,  ..., -0.0174,  0.0366, -0.0247],\n","        [-0.0196, -0.0242, -0.0138,  ..., -0.0290,  0.0247, -0.0078],\n","        [ 0.0054, -0.0330, -0.0269,  ..., -0.0053,  0.0073,  0.0095],\n","        ...,\n","        [-0.0219, -0.0336,  0.0166,  ...,  0.0306, -0.0301,  0.0158],\n","        [ 0.0315, -0.0358, -0.0382,  ...,  0.0023,  0.0336, -0.0364],\n","        [-0.0313, -0.0397, -0.0094,  ..., -0.0210, -0.0014,  0.0178]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","debug head param Parameter containing:\n","tensor([[ 0.0351, -0.0543, -0.0634,  ..., -0.0175,  0.0367, -0.0247],\n","        [-0.0198, -0.0251, -0.0131,  ..., -0.0290,  0.0251, -0.0083],\n","        [ 0.0059, -0.0324, -0.0273,  ..., -0.0056,  0.0069,  0.0091],\n","        ...,\n","        [-0.0220, -0.0342,  0.0163,  ...,  0.0313, -0.0300,  0.0156],\n","        [ 0.0320, -0.0355, -0.0380,  ...,  0.0021,  0.0335, -0.0369],\n","        [-0.0305, -0.0391, -0.0097,  ..., -0.0210, -0.0016,  0.0173]],\n","       device='cuda:0', requires_grad=True)\n","Using origin parameters for the ghost differentiation trick......\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","debug head param Parameter containing:\n","tensor([[ 0.0352, -0.0543, -0.0633,  ..., -0.0176,  0.0368, -0.0247],\n","        [-0.0198, -0.0252, -0.0131,  ..., -0.0290,  0.0251, -0.0083],\n","        [ 0.0059, -0.0323, -0.0271,  ..., -0.0055,  0.0069,  0.0091],\n","        ...,\n","        [-0.0219, -0.0341,  0.0163,  ...,  0.0313, -0.0298,  0.0156],\n","        [ 0.0320, -0.0357, -0.0380,  ...,  0.0021,  0.0334, -0.0369],\n","        [-0.0304, -0.0391, -0.0097,  ..., -0.0210, -0.0016,  0.0172]],\n","       device='cuda:0', requires_grad=True)\n"]}],"source":["!python3 differentially_private/baseline_train.py --config=configs/dp/cifar10lpfull.yaml --log_dir=logs/moco2_200ep_dplp5ft5_cifar10_lr_0.025_nm_0.3_mt_0_sd_2 --project_name=dplpftyes_cifar10 --group_name=dplpftyes_cifar10 --run_name moco2_200ep_dp_lp5ft5_cifar10_lr_0.025_nm_0.3_mt_0_sd_2 --optimizer.args.lr=0.025 --full_ft_epoch=5 --no_wandb --seed 2 --privacy_engine.args.noise_multiplier=0.3 --model.args.checkpoint_path='cl/moco_v2_200ep_pretrain.pth.tar'"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}